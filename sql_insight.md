# ‚úÖ What Your Text-to-SQL System Does
<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/b176d0e2-1610-49b5-a250-13218288410d" />


Your pipeline allows a natural language question (like ‚ÄúWhat are the top 5 artists by album count?‚Äù) to be:

Transformed into a SQL query using LangChain + Azure OpenAI
Executed against an SQLite database (Chinook.db)
Answer returned as SQL output (rows + column names)
Follow-up insights generated by LLM
Final result stored in MongoDB (sql_history)
# üîÑ End-to-End Workflow

## 1. User Sends a Question
Endpoint:

@app.post("/query/")
Request JSON:

{
  "question": "What are the top 5 artists by album count?",
  "selected_tables": ["albums", "artists"]
}
## 2. LangChain Generates SQL
This is handled using:

agent_executor = create_sql_query_chain(llm, db)
query = agent_executor.invoke({"question": question})
create_sql_query_chain() from LangChain uses:
LLMChain under the hood
LangChain SQL agent prompt template
AzureOpenAI (llm) as the LLM
Based on the schema of db = SQLDatabase.from_uri("sqlite:///data/Chinook.db")
Sample output (SQL):

SELECT artists.Name, COUNT(albums.AlbumId) as AlbumCount
FROM artists
JOIN albums ON artists.ArtistId = albums.ArtistId
GROUP BY artists.Name
ORDER BY AlbumCount DESC
LIMIT 5;
## 3. SQL Is Executed
execute_query = QuerySQLDataBaseTool(db=db, llm=llm)
result = execute_query.invoke({"query": query})
The output is a list of tuples, e.g.:

[
    ("Led Zeppelin", 12),
    ("AC/DC", 10),
    ...
]
## 4. Insights Generated from Data
insights = llm.invoke(f"Analyze the following data and provide insights ...")
Prompt looks like:

"Analyze the following data and provide insights related to sales trends and projections. The data is: [...]"
## 5. Column Names Extraction via LLM
Another LLM call to infer column names from the SQL query:

column_name = llm.invoke(f"Given this SQL query: {query}... Provide only the names of columns as a Python list.")
Then extracted using:

extracted_content_list = eval(extracted_content)
## 6. Data Is Rounded + Combined
combined_result = [tuple(extracted_content_list)] + result
# rounding logic
Final structure becomes like:

[
  ("Artist Name", "Album Count"),
  ("Led Zeppelin", 12),
  ...
]
## 7. Result Stored in MongoDB
sql_history.insert_one({
  "id": user_id,
  "question": question,
  "query": query,
  "result": combined_result_str,
  "insights": insights
})
üìÇ Files Involved in This Flow

You've already included everything in main.py ‚Äî but you can share the following if you want to make the SQL agent smarter:

### 1. Chinook.db file
To verify schema (albums, artists, tracks, etc.)
Useful if you want to pre-load schema into prompts
### 2. Custom Prompt Template (optional)
If you used a custom SQL prompt with create_sql_query_chain()

üß™ Sample Code You Can Test in Isolation

from langchain.sql_database import SQLDatabase
from langchain.chains import create_sql_query_chain
from langchain_openai import AzureOpenAI
import os

db = SQLDatabase.from_uri("sqlite:///data/Chinook.db")
llm = AzureOpenAI(deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
                  model_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
                  temperature=0)

chain = create_sql_query_chain(llm, db)
question = "What are the top 5 customers by invoice amount?"
sql = chain.invoke({"question": question})
print("Generated SQL:", sql)


https://sdmntprnorthcentralus.oaiusercontent.com/files/00000000-9704-622f-a56e-6e2278329bee/raw?se=2025-07-10T18%3A02%3A59Z&sp=r&sv=2024-08-04&sr=b&scid=d229fc3b-5f0b-538f-bf1a-2cd74b213e2a&skoid=add8ee7d-5fc7-451e-b06e-a82b2276cf62&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-10T01%3A34%3A46Z&ske=2025-07-11T01%3A34%3A46Z&sks=b&skv=2024-08-04&sig=j2fHzUHtUsRWMPm1xzW5xudZ6q1OX%2Bj0CehpG1pMse0%3D<img width="1024" height="1024" alt="image" src="https://github.com/user-attachments/assets/1aaabc83-6331-4f05-9f75-f2cd36722f73" />



# üß† Goal

Allow users to ask natural language questions, convert them to SQL queries, execute those queries on a database, analyze the results using an LLM, and return both query + insights + tabular data to the frontend.

## ‚úÖ Components Involved

Component	Purpose
FastAPI	Handles HTTP API endpoints
LangChain SQL Agent	Converts NL ‚Üí SQL
Azure OpenAI (LLM)	Generates SQL + insights
SQLDatabase (Chinook.db)	Source of truth (sample SQLite database)
MongoDB	Logs query history
OAuth2 + JWT	User session management
CORS Middleware	Cross-origin support (for React frontend)
üîÑ Detailed Flow: Step-by-Step

## 1. User logs in via Google
@app.post("/googlelogin/")
JWT token is received ‚Üí decoded.
If user is new ‚Üí insert in MongoDB (users).
Session is stored (request.session["user_id"] = id).
## 2. User selects tables (optional)
GET /tables/
Returns usable table names from the Chinook.db database.

## 3. User asks a question
POST /query/
Request:

{
  "question": "Show total sales by country",
  "selected_tables": ["invoices", "customers"]
}
## 4. Question is modified with table hint (if provided)
question += f" strictly using {selected_tables_str} tables"
Ensures generated SQL is scoped only to selected tables.

## 5. LangChain SQL Agent generates SQL
query = agent_executor.invoke({"question": question})
Uses AzureOpenAI as the LLM.
Understands schema via SQLDatabase.from_uri().
Outputs SQL like:
SELECT BillingCountry, SUM(Total) FROM invoices GROUP BY BillingCountry;
## 6. SQL is executed
result = execute_query.invoke({"query": query})
Uses QuerySQLDataBaseTool (LangChain tool).
Runs query against SQLite (Chinook.db).
Returns data like:
[('USA', 2500.50), ('Canada', 1230.00)]
## 7. Column headers are extracted
column_name = llm.invoke("Given this SQL query... Provide column names as a Python list")
‚Üí Extracts:

['Country', 'Total']
This is used for tabular formatting on the frontend.

## 8. Data + Headers are combined
combined_result = [tuple(extracted_content_list)] + result
‚Üí Now the result looks like:

[('Country', 'Total'), ('USA', 2500.50), ('Canada', 1230.00)]
## 9. Insights are generated
insights = llm.invoke(
    f"Analyze the following data and provide insights related to sales trends and projections..."
)
LLM outputs:

"The USA has the highest sales, followed by Canada..."
## 10. Round off numeric values
combined_result[i] = tuple(round(val, 2) if isinstance(val, float) else val ...)
Ensures clean display (like 2500.5 ‚Üí 2500.50).

## 11. Result is saved to history
sql_history.insert_one({
    "id": user_id,
    "question": question,
    "query": query,
    "result": str(combined_result),
    "insights": insights
})
## 12. Response returned to frontend
{
  "question": "...",
  "query": "...",
  "result": [["Country", "Total"], ["USA", 2500.50]],
  "insights": "USA leads in sales..."
}
Frontend may now:

Display a table using result.
Show insights as text.
Plot bar charts from result.
üß† Extra Features

üîÅ History Retrieval
GET /history/
Returns past query logs for a user:

question
query
result
insights
üõ°Ô∏è Authentication
JWT-based, stored in session.
All query endpoints are protected by:
Depends(get_current_user)
üß± Technologies Used

Layer	Tools
API	FastAPI
LLM	Azure OpenAI + LangChain
Vector Tools	Not used here (used in document/audio)
Database	SQLite (for SQL execution), MongoDB (for logging)
Security	OAuth2 + JWT
Frontend integration	CORS-enabled (localhost:3000)

