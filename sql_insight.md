# ‚úÖ What Your Text-to-SQL System Does
<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/b176d0e2-1610-49b5-a250-13218288410d" />


Your pipeline allows a natural language question (like ‚ÄúWhat are the top 5 artists by album count?‚Äù) to be:

Transformed into a SQL query using LangChain + Azure OpenAI
Executed against an SQLite database (Chinook.db)
Answer returned as SQL output (rows + column names)
Follow-up insights generated by LLM
Final result stored in MongoDB (sql_history)
# üîÑ End-to-End Workflow

## 1. User Sends a Question
Endpoint:

@app.post("/query/")
Request JSON:

{
  "question": "What are the top 5 artists by album count?",
  "selected_tables": ["albums", "artists"]
}
## 2. LangChain Generates SQL
This is handled using:

agent_executor = create_sql_query_chain(llm, db)
query = agent_executor.invoke({"question": question})
create_sql_query_chain() from LangChain uses:
LLMChain under the hood
LangChain SQL agent prompt template
AzureOpenAI (llm) as the LLM
Based on the schema of db = SQLDatabase.from_uri("sqlite:///data/Chinook.db")
Sample output (SQL):

SELECT artists.Name, COUNT(albums.AlbumId) as AlbumCount
FROM artists
JOIN albums ON artists.ArtistId = albums.ArtistId
GROUP BY artists.Name
ORDER BY AlbumCount DESC
LIMIT 5;
## 3. SQL Is Executed
execute_query = QuerySQLDataBaseTool(db=db, llm=llm)
result = execute_query.invoke({"query": query})
The output is a list of tuples, e.g.:

[
    ("Led Zeppelin", 12),
    ("AC/DC", 10),
    ...
]
## 4. Insights Generated from Data
insights = llm.invoke(f"Analyze the following data and provide insights ...")
Prompt looks like:

"Analyze the following data and provide insights related to sales trends and projections. The data is: [...]"
## 5. Column Names Extraction via LLM
Another LLM call to infer column names from the SQL query:

column_name = llm.invoke(f"Given this SQL query: {query}... Provide only the names of columns as a Python list.")
Then extracted using:

extracted_content_list = eval(extracted_content)
## 6. Data Is Rounded + Combined
combined_result = [tuple(extracted_content_list)] + result
# rounding logic
Final structure becomes like:

[
  ("Artist Name", "Album Count"),
  ("Led Zeppelin", 12),
  ...
]
## 7. Result Stored in MongoDB
sql_history.insert_one({
  "id": user_id,
  "question": question,
  "query": query,
  "result": combined_result_str,
  "insights": insights
})
üìÇ Files Involved in This Flow

You've already included everything in main.py ‚Äî but you can share the following if you want to make the SQL agent smarter:

### 1. Chinook.db file
To verify schema (albums, artists, tracks, etc.)
Useful if you want to pre-load schema into prompts
### 2. Custom Prompt Template (optional)
If you used a custom SQL prompt with create_sql_query_chain()

üß™ Sample Code You Can Test in Isolation

from langchain.sql_database import SQLDatabase
from langchain.chains import create_sql_query_chain
from langchain_openai import AzureOpenAI
import os

db = SQLDatabase.from_uri("sqlite:///data/Chinook.db")
llm = AzureOpenAI(deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
                  model_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
                  temperature=0)

chain = create_sql_query_chain(llm, db)
question = "What are the top 5 customers by invoice amount?"
sql = chain.invoke({"question": question})
print("Generated SQL:", sql)
